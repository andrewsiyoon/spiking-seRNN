{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/IwbXIkxlDsGdXpt42Vqw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrewsiyoon/spiking-seRNN/blob/main/Optimizing_time_constants.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2LbsMh3P7mL"
      },
      "outputs": [],
      "source": [
        "#Imports ----------\n",
        "\n",
        "import snntorch as snn\n",
        "from snntorch import spikeplot as splt\n",
        "from snntorch import spikegen\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural heterogeneity leads to robust learning\n",
        "\n",
        "- Homogeneous/heterogeneous initializations\n",
        "    - Membrane time constant: gamma(3, tau/3)\n",
        "    - Synaptic time constant: gamma(3, tau/3)\n",
        "\n",
        "- Synaptic time constant (current)\n",
        "    - This time constant seems to modulate the input current \n",
        "    - Spike train: summation of all spikes emitted by a neuron in layer l-1 within a finite time period\n",
        "    - Input current into a neuron i: spike trains of all l-1 neurons connected to neuron i (modulated by feedforward synaptic weight W) + spike trains of all recurrent l neurons connected to neuron i (modulated by recurrent synaptic weight V). -- then, modulated by the synaptic time constant\n",
        "    - I[t+1] = α * I[t] + Σ(W * S(l-1)[t]) + Σ (V * S(l)[t])\n",
        "        - α = exp(-∆t / τ(s))\n",
        "        - W = feedforward synaptic weights from layer l-1\n",
        "        - V = recurrent synaptic weights from layer l\n",
        "\n",
        "- Membrane time constant (membrane)\n",
        "    - β = exp(-∆t / τ(m)) -- β is for the membrane time constant\n",
        "    - U[t+1] = β(U[t] - U[0]) + U[0] + (1-β) * I[t] - (U[threshold] - U[reset]) * S[t]\n",
        "        - The last term (U[threshold] - U[reset]) * S[t] is the reset term for the membrane potential that only activates when a spike occurs\n",
        "        - When S[t] = 1, subtract (U[thr] - U[r]) from the membrane potential\n",
        "        - U[0] = resting potential\n",
        "\n",
        "- Spiking equation (spike)\n",
        "    - S[t] = 1 if U[t] - U[thr] ≥ 0 and = 0 if U[t] = U[thr] < 0.\n",
        "        - This step function is followed for the forward pass. \n",
        "    - In the backwards pass, use surrogate gradient descent (BPTT):\n",
        "        - σ(𝑈(𝑙)𝑖)=𝑈(𝑙)𝑖1+𝜌|U(𝑙)𝑖|\n",
        "\n",
        "- Gradient descent optimizes W and V weights, and the spiking parameters U[thr], U[0], and U[r].\n",
        "- Training α and β indirectly trains the synaptic and membrane time constants:\n",
        "    - Clipping function after every update (keep within plausible range):\n",
        "        - Minimum constraint = exp(-1/3)\n",
        "        - Maximum constraint = 0.995\n",
        "    - Used automatic differentiation on Pytorch and Adam optimizer with learning rate 10^-3 and betas (0.9, 0.999)\n",
        "        - Nothing else mentioned -- need to look into the code and see how they made α and β actually trainable"
      ],
      "metadata": {
        "id": "05LlIzd2QPIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple LIF model ----------\n",
        "\n",
        "def leaky_integrate_neuron(U, time_step=1e-3, I=0, R=5e7, C=1e-10):\n",
        "    tau = R*C #Change tau to see how the decay rate changes (as tau increases, decay rate decreases)\n",
        "    U = U + (time_step/tau)*(-U + I*R)\n",
        "    return U\n",
        "\n",
        "num_steps = 100\n",
        "U = 0.9\n",
        "U_trace = []  #Empty matrix that keeps a record of U for plotting\n",
        "\n",
        "for step in range(num_steps):\n",
        "    U_trace.append(U)\n",
        "    U = leaky_integrate_neuron(U)  #Solve next step of U\n",
        "\n",
        "plot_mem(U_trace, \"Leaky Neuron Model\")"
      ],
      "metadata": {
        "id": "fTUAy9p6QTXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Simplified LIF model ----------\n",
        "\n",
        "#Beta (β) is the decay rate. β = (1 - ∆t / τ)\n",
        "#As τ (RC time constant) increases, decay decreases. In the above equation, as τ increases β approaches 1.\n",
        "#U(t + ∆t) = β * U(t). U(t) at each time step changes by a factor of β.\n",
        "\n",
        "#Discretizing time: results in the following equation,\n",
        "#U[t+1] = βU[t] + (1-β) * I(in) * [t+1] + S[t] * U(threshold)\n",
        "#The input current is weighted by a factor of (1-β), and the input current weights are learnable in a neural network.\n",
        "#Can replace I(in) with X[t] (input voltage/spike) and (1-β) with W, which scales the input spike. \n",
        "#W is a learnable parameter that is updated independently of β -- not sure why!\n",
        "#W * X[t+1] collectively make up the \"input.\"\n",
        "\n",
        "\n",
        "def leaky_integrate_and_fire(mem, x, w, beta, threshold=1):\n",
        "  spk = (mem > threshold) # if membrane exceeds threshold, spk=1, else, 0\n",
        "  mem = beta * mem + w*x - spk*threshold\n",
        "  return spk, mem\n",
        "\n",
        "#Define β using discretized time-dependent equation (3) -- instead of hardcoding, which they do in later simulations\n",
        "\n",
        "delta_t = torch.tensor(1e-3)\n",
        "tau = torch.tensor(5e-3)\n",
        "beta = torch.exp(-delta_t/tau)\n",
        "\n",
        "num_steps = 200\n",
        "\n",
        "#Initialize inputs/outputs + small step current input\n",
        "x = torch.cat((torch.zeros(10), torch.ones(190)*0.5), 0)\n",
        "mem = torch.zeros(1)\n",
        "spk_out = torch.zeros(1)\n",
        "mem_rec = []\n",
        "spk_rec = []\n",
        "\n",
        "#Neuron simulation\n",
        "for step in range(num_steps):\n",
        "  spk, mem = leaky_integrate_and_fire(mem, x[step], w=w, beta=beta)\n",
        "  mem_rec.append(mem)\n",
        "  spk_rec.append(spk)\n",
        "\n",
        "#Convert lists to tensors\n",
        "mem_rec = torch.stack(mem_rec)\n",
        "spk_rec = torch.stack(spk_rec)\n",
        "\n",
        "plot_cur_mem_spk(x*w, mem_rec, spk_rec, thr_line=1,ylim_max1=0.5,\n",
        "                 title=\"LIF Neuron Model With Weighted Step Voltage\")\n"
      ],
      "metadata": {
        "id": "34TsJrD9QVQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting settings ----------\n",
        "\n",
        "def plot_mem(mem, title=False):\n",
        "  if title:\n",
        "    plt.title(title)\n",
        "  plt.plot(mem)\n",
        "  plt.xlabel(\"Time step\")\n",
        "  plt.ylabel(\"Membrane Potential\")\n",
        "  plt.xlim([0, 50])\n",
        "  plt.ylim([0, 1])\n",
        "  plt.show()\n",
        "\n",
        "def plot_step_current_response(cur_in, mem_rec, vline1):\n",
        "  fig, ax = plt.subplots(2, figsize=(8,6),sharex=True)\n",
        "\n",
        "  # Plot input current\n",
        "  ax[0].plot(cur_in, c=\"tab:orange\")\n",
        "  ax[0].set_ylim([0, 0.2])\n",
        "  ax[0].set_ylabel(\"Input Current ($I_{in}$)\")\n",
        "  ax[0].set_title(\"Lapicque's Neuron Model With Step Input\")\n",
        "\n",
        "  # Plot membrane potential\n",
        "  ax[1].plot(mem_rec)\n",
        "  ax[1].set_ylim([0, 0.6]) \n",
        "  ax[1].set_ylabel(\"Membrane Potential ($U_{mem}$)\")\n",
        "\n",
        "  if vline1:\n",
        "    ax[1].axvline(x=vline1, ymin=0, ymax=2.2, alpha = 0.25, linestyle=\"dashed\", c=\"black\", linewidth=2, zorder=0, clip_on=False)\n",
        "  plt.xlabel(\"Time step\")\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plot_current_pulse_response(cur_in, mem_rec, title, vline1=False, vline2=False, ylim_max1=False):\n",
        "\n",
        "  fig, ax = plt.subplots(2, figsize=(8,6),sharex=True)\n",
        "\n",
        "  # Plot input current\n",
        "  ax[0].plot(cur_in, c=\"tab:orange\")\n",
        "  if not ylim_max1:\n",
        "    ax[0].set_ylim([0, 0.2])\n",
        "  else:\n",
        "    ax[0].set_ylim([0, ylim_max1])\n",
        "  ax[0].set_ylabel(\"Input Current ($I_{in}$)\")\n",
        "  ax[0].set_title(title)\n",
        "\n",
        "  # Plot membrane potential\n",
        "  ax[1].plot(mem_rec)\n",
        "  ax[1].set_ylim([0, 1])\n",
        "  ax[1].set_ylabel(\"Membrane Potential ($U_{mem}$)\")\n",
        "\n",
        "  if vline1:\n",
        "    ax[1].axvline(x=vline1, ymin=0, ymax=2.2, alpha = 0.25, linestyle=\"dashed\", c=\"black\", linewidth=2, zorder=0, clip_on=False)\n",
        "  if vline2:\n",
        "    ax[1].axvline(x=vline2, ymin=0, ymax=2.2, alpha = 0.25, linestyle=\"dashed\", c=\"black\", linewidth=2, zorder=0, clip_on=False)\n",
        "  plt.xlabel(\"Time step\")\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "def compare_plots(cur1, cur2, cur3, mem1, mem2, mem3, vline1, vline2, vline3, vline4, title):\n",
        "  # Generate Plots\n",
        "  fig, ax = plt.subplots(2, figsize=(8,6),sharex=True)\n",
        "\n",
        "  # Plot input current\n",
        "  ax[0].plot(cur1)\n",
        "  ax[0].plot(cur2)\n",
        "  ax[0].plot(cur3)\n",
        "  ax[0].set_ylim([0, 0.2])\n",
        "  ax[0].set_ylabel(\"Input Current ($I_{in}$)\")\n",
        "  ax[0].set_title(title)\n",
        "\n",
        "  # Plot membrane potential\n",
        "  ax[1].plot(mem1)\n",
        "  ax[1].plot(mem2)\n",
        "  ax[1].plot(mem3)\n",
        "  ax[1].set_ylim([0, 1])\n",
        "  ax[1].set_ylabel(\"Membrane Potential ($U_{mem}$)\")\n",
        "\n",
        "  ax[1].axvline(x=vline1, ymin=0, ymax=2.2, alpha = 0.25, linestyle=\"dashed\", c=\"black\", linewidth=2, zorder=0, clip_on=False)\n",
        "  ax[1].axvline(x=vline2, ymin=0, ymax=2.2, alpha = 0.25, linestyle=\"dashed\", c=\"black\", linewidth=2, zorder=0, clip_on=False)\n",
        "  ax[1].axvline(x=vline3, ymin=0, ymax=2.2, alpha = 0.25, linestyle=\"dashed\", c=\"black\", linewidth=2, zorder=0, clip_on=False)\n",
        "  ax[1].axvline(x=vline4, ymin=0, ymax=2.2, alpha = 0.25, linestyle=\"dashed\", c=\"black\", linewidth=2, zorder=0, clip_on=False)\n",
        "\n",
        "  plt.xlabel(\"Time step\")\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "def plot_cur_mem_spk(cur, mem, spk, thr_line=False, vline=False, title=False, ylim_max2=1.25):\n",
        "  # Generate Plots\n",
        "  fig, ax = plt.subplots(3, figsize=(8,6), sharex=True, \n",
        "                        gridspec_kw = {'height_ratios': [1, 1, 0.4]})\n",
        "\n",
        "  # Plot input current\n",
        "  ax[0].plot(cur, c=\"tab:orange\")\n",
        "  ax[0].set_ylim([0, 0.4])\n",
        "  ax[0].set_xlim([0, 200])\n",
        "  ax[0].set_ylabel(\"Input Current ($I_{in}$)\")\n",
        "  if title:\n",
        "    ax[0].set_title(title)\n",
        "\n",
        "  # Plot membrane potential\n",
        "  ax[1].plot(mem)\n",
        "  ax[1].set_ylim([0, ylim_max2]) \n",
        "  ax[1].set_ylabel(\"Membrane Potential ($U_{mem}$)\")\n",
        "  if thr_line:\n",
        "    ax[1].axhline(y=thr_line, alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
        "  plt.xlabel(\"Time step\")\n",
        "\n",
        "  # Plot output spike using spikeplot\n",
        "  splt.raster(spk, ax[2], s=400, c=\"black\", marker=\"|\")\n",
        "  if vline:\n",
        "    ax[2].axvline(x=vline, ymin=0, ymax=6.75, alpha = 0.15, linestyle=\"dashed\", c=\"black\", linewidth=2, zorder=0, clip_on=False)\n",
        "  plt.ylabel(\"Output spikes\")\n",
        "  plt.yticks([]) \n",
        "\n",
        "  plt.show()\n",
        "\n",
        "def plot_spk_mem_spk(spk_in, mem, spk_out, title):\n",
        "  # Generate Plots\n",
        "  fig, ax = plt.subplots(3, figsize=(8,6), sharex=True, \n",
        "                        gridspec_kw = {'height_ratios': [0.4, 1, 0.4]})\n",
        "\n",
        "  # Plot input current\n",
        "  splt.raster(spk_in, ax[0], s=400, c=\"black\", marker=\"|\")\n",
        "  ax[0].set_ylabel(\"Input Spikes\")\n",
        "  ax[0].set_title(title)\n",
        "  plt.yticks([]) \n",
        "\n",
        "  # Plot membrane potential\n",
        "  ax[1].plot(mem)\n",
        "  ax[1].set_ylim([0, 1])\n",
        "  ax[1].set_ylabel(\"Membrane Potential ($U_{mem}$)\")\n",
        "  ax[1].axhline(y=0.5, alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
        "  plt.xlabel(\"Time step\")\n",
        "\n",
        "  # Plot output spike using spikeplot\n",
        "  splt.raster(spk_rec, ax[2], s=400, c=\"black\", marker=\"|\")\n",
        "  plt.ylabel(\"Output spikes\")\n",
        "  plt.yticks([]) \n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plot_reset_comparison(spk_in, mem_rec, spk_rec, mem_rec0, spk_rec0):\n",
        "  # Generate Plots to Compare Reset Mechanisms\n",
        "  fig, ax = plt.subplots(nrows=3, ncols=2, figsize=(10,6), sharex=True, \n",
        "                        gridspec_kw = {'height_ratios': [0.4, 1, 0.4], 'wspace':0.05})\n",
        "\n",
        "  # Reset by Subtraction: input spikes\n",
        "  splt.raster(spk_in, ax[0][0], s=400, c=\"black\", marker=\"|\")\n",
        "  ax[0][0].set_ylabel(\"Input Spikes\")\n",
        "  ax[0][0].set_title(\"Reset by Subtraction\")\n",
        "  ax[0][0].set_yticks([])\n",
        "\n",
        "  # Reset by Subtraction: membrane potential \n",
        "  ax[1][0].plot(mem_rec)\n",
        "  ax[1][0].set_ylim([0, 0.7])\n",
        "  ax[1][0].set_ylabel(\"Membrane Potential ($U_{mem}$)\")\n",
        "  ax[1][0].axhline(y=0.5, alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
        "\n",
        "  # Reset by Subtraction: output spikes\n",
        "  splt.raster(spk_rec, ax[2][0], s=400, c=\"black\", marker=\"|\")\n",
        "  ax[2][0].set_yticks([])\n",
        "  ax[2][0].set_xlabel(\"Time step\")\n",
        "  ax[2][0].set_ylabel(\"Output Spikes\")\n",
        "\n",
        "  # Reset to Zero: input spikes\n",
        "  splt.raster(spk_in, ax[0][1], s=400, c=\"black\", marker=\"|\")\n",
        "  ax[0][1].set_title(\"Reset to Zero\")\n",
        "  ax[0][1].set_yticks([])\n",
        "\n",
        "  # Reset to Zero: membrane potential\n",
        "  ax[1][1].plot(mem_rec0)\n",
        "  ax[1][1].set_ylim([0, 0.7])\n",
        "  ax[1][1].axhline(y=0.5, alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
        "  ax[1][1].set_yticks([])\n",
        "  ax[2][1].set_xlabel(\"Time step\")\n",
        "\n",
        "  # Reset to Zero: output spikes\n",
        "  splt.raster(spk_rec0, ax[2][1], s=400, c=\"black\", marker=\"|\")\n",
        "  ax[2][1].set_yticks([])\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "UPj3SdLQQXaz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}